<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[]]></title>
  <link href="/atom.xml" rel="self"/>
  <link href="/"/>
  <updated>2012-08-23T15:10:53-04:00</updated>
  <id>/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[HOWTO (Video) Simple KVM Virtualization, a Command Line Demonstration]]></title>
    <link href="/2012/04/04/HOWTO-simple-kvm-virtualization-a-command-line-demonstration.html"/>
    <updated>2012-04-04T00:00:00-04:00</updated>
    <id>/2012/04/04/HOWTO-simple-kvm-virtualization-a-command-line-demonstration</id>
    <content type="html"><![CDATA[<h1 id='howto_video_simple_kvm_virtualization_a_command_line_demonstration'>HOWTO (Video) Simple KVM Virtualization, a Command Line Demonstration</h1>

<p>2012 Apr 4</p>

<p>A simple demonstration using KVM (Kernel-based Virtual Machine) from the command line interface.</p>

<p>Sorry for the slight graphics artefacts, I was testing out some screencast software for the first time.</p>

<p>Watch it on youtube, <a href='http://www.youtube.com/watch?v=aN8lb2O-wHs'>here</a>.</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2 cent Linux tip using find and tar for a selective backup]]></title>
    <link href="/2011/07/11/2-cent-linux-tip-using-find-and-tar-for-a-selective-backup.html"/>
    <updated>2011-07-11T00:00:00-04:00</updated>
    <id>/2011/07/11/2-cent-linux-tip-using-find-and-tar-for-a-selective-backup</id>
    <content type="html"><![CDATA[<h1 id='2_cent_linux_tip_using_find_and_tar_for_a_selective_backup'>2 cent Linux tip using find and tar for a selective backup</h1>

<p>2011 Jul 11</p>

<p>So I&#39;m blowing away, and re-installing, my Steam Bottle on <a href='http://codeweavers.com'>Codeweaver&#39;s</a> Crossover games. I was hoping to get some in-game overlay support for the Community/Friends features of Steam. I really really want to hang on to Team Fortress/Left 4 Dead settings though.</p>

<p>Using the <code>find</code> command we can solve this problem fairly easy.</p>

<p>So the basic requirements in this scenario boil down to finding all the config files under the <code>~/.cxgames</code> tree. I have an <code>~/etc</code> directory to keep a backup of important things such as settings and handy scripts. I will copy my tar file to the <code>~/etc</code> directory so I can find it easily later. However, I don&#8217;t want every <code>*.cfg</code> file under my Steam bottle, just the ones for those specific games (Team Fortress and Left 4 Dead). When I run the following command, I&#39;ll discover those games have a common top-level directory, <em>~/.cxgames/Steam/drive_c/Program Files/Steam/steamapps</em>.</p>
<div>
  <pre><code class='bash'>find ~/.cxgames -name &quot;*.cfg&quot;</code></pre>
</div>
<p>When I run the following command, however, I&#8217;ll get an error due to spaces in the directory/filename structure. Note the backslash in &#8220;Program Files&#8221; is an escaped space for the shell to properly interpret this.</p>
<div>
  <pre><code class='bash'>find .cxgames/Steam/drive_c/Program\ Files/Steam/steamapps/ | xargs tar -rf ~/etc/steam-settings.tar</code></pre>
</div>
<p>The find command has a switch <code>-print0</code> to deal with this, and <code>xargs</code> will process this find output format with the <code>-0</code> flag. The <code>-print0</code> and <code>-0</code> flags tell these system utilities to print or use null-terminated strings, making it easier for shell utilities to consume the spaces in the filenames. Therefore the following command will get the files I need:</p>
<div>
  <pre><code class='bash'>find ~/.cxgames/Steam/drive_c/Program Files/Steam/steamapps/ -name &quot;*.cfg&quot; -print0 | xargs -0 tar -rf ~/etc/steam-settings.tar</code></pre>
</div>
<p>Restoring is as simple as running the following command from within my home directory.</p>
<div>
  <pre><code class='bash'>tar xvf ~/etc/steam-settings.tar</code></pre>
</div>
<p>Perhaps some day we&#8217;ll have a Linux steam client, and a promotional TF2 item named the <strong>Unix Pipe</strong>.</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HOWTO Using rsync to move a mountain of data]]></title>
    <link href="/2011/04/16/HOWTO-Using-rsync-to-move-a-mountain-of-data.html"/>
    <updated>2011-04-16T00:00:00-04:00</updated>
    <id>/2011/04/16/HOWTO-Using-rsync-to-move-a-mountain-of-data</id>
    <content type="html"><![CDATA[<h1 id='howto_using_rsync_to_move_a_mountain_of_data'>HOWTO Using rsync to move a mountain of data</h1>

<p>2011 Mar 16</p>

<p>In this installment of my blog, I want to document the proper use of rsync for folks who are tasked with moving a large amount of data. I&#39;ll even show you a few things you can do from the command line interface to extend the built-in capability of rsync using a little bash-scripting trickery.</p>

<p>I use rsync to migrate Oracle databases between servers at least a few times per year. In a snap, its one of the easiest ways to clone a database from a Production server to a Pre-Production/Development server or even a Virtual Machine. You don&#8217;t have to have a fancy Fibre-Channel or iSCSI storage array attached to both servers, in order to do a data LUN clone, thanks to rsync.</p>

<p>I hope you enjoy this in-depth article. Please feel free to comment: if you need clarification, find it useful, or something I wrote is just plain wrong.</p>

<h2 id='the_tools'>The Tools</h2>

<p>Three things you&#8217;ll need for this exercise:</p>

<ol>
<li><code>screen</code> - lets you detach a console session, and can be re-attached after logging out and walking away.</li>

<li><code>rsync</code> - the swiss-army knife of copy/archiving programs.</li>

<li><code>data</code> - any will do. Whether its a large group of /home directories, or even a live Oracle database.</li>
</ol>

<h2 id='basics_of_screen'>Basics of screen</h2>

<ol>
<li>Simply type <code>screen</code> in the command-line interface.</li>

<li>Kick off a large rsync job that may take several hours to finish</li>

<li><code>ctrl-a d</code> detaches your screen session. You may then proceed to logout, walk away, and go grab a lunch, or two.</li>

<li>Log back in to the server later, and re-attach your session by running <code>screen -r</code>. * If your connection to the server was interrupted by an unreliable network, screen may throw an error saying the session is already attached, however screen -dr will de-tach and re-attach the session with no problem.</li>
</ol>

<h2 id='basics_of_rsync'>Basics of rsync</h2>

<p>There is a daunting amount of options to be found in the <code>rsync</code> manpage. An important point to remember is what no-slash and trailing slashes on directories mean.</p>

<p>For instance if I want to copy everything within a folder named <code>/home</code>, I would use <code>rsync -av /home/ /path/to/destination</code> to copy the files within <code>/home</code>, to the folder <code>/path/to/destination</code>.</p>

<p>On the other hand, if I want to copy the folder <code>/home</code> itself to <code>/path/to/destination</code>, then I would use <code>rsync -av /home /path/to/destination</code>, which will then create the folder <code>/path/to/destination/home</code>.</p>

<p>Here are a few of the most important command-line options to remember.</p>

<ul>
<li>
<p><code>-v</code>: verbose, will tell you what file its on, how many left to check, etc.</p>
</li>

<li>
<p><code>-a</code>: archive, will set most of the preferable options, this is shorthand for -rlptgoD. If in doubt, you most always want the -a option.</p>

<ul>
<li><code>-r</code>: recursive</li>

<li><code>-l</code>: copy symlinks as files, not the file to which they point. Why do you want this? It prevents your rsync job from looping back to a directory above itself, causing an infinite loop, in the case there are a few unruly symlinks in your filesystem tree.</li>

<li><code>-p</code>: preserve permissions</li>

<li><code>-t</code>: preserve modification timestamps</li>

<li><code>-g</code>: preserve group ownership. rsync is smart enough to change the group ID by name, rather than numerical group ID on the destination.</li>

<li><code>-o</code>: preserve ownership. Same behavior applies to user ID by name, rather than numerical ID.</li>

<li><code>-D</code>: preserve special files. Such as device files, named pipes, etc.</li>
</ul>
</li>
</ul>

<p>Some other useful switches</p>

<ul>
<li><code>--progress</code>: gives you per-file data transfer rates, and spinning progress bars if you&#39;re into that sort of thing.</li>

<li><code>--stats</code>: gives you a nice summary rate, and speed-up rate at the end of the job.</li>
</ul>

<h2 id='set_up_a_rsync_daemon'>Set up a rsync daemon</h2>

<p>If you are cloning a database or migrating a complex ERP system, the fastest way to do that is export a root share for your destination host, by defining it in rsyncd.conf. I typically set up a temporary read-only rsync daemon on the production host. The reasoning for that is the the client end of rsync will consume more memory as it indexes the list of files to transfer. Therefore rsync should have less impact by running the job from a pre-production host, while the daemon runs on your production server.</p>

<p>Anyway, the configuration files for the temporary rsync daemon on your production system should look something like this.</p>
<div>
  <pre><code class='bash'>#/etc/rsyncd.conf
    syslog facility = local3
    read only = yes list = yes
    auth users = root
    secrets file = /etc/rsyncd.secrets
    hosts allow = 1.2.3.4/32
    uid = 0
    gid = 0

    [root]
    comment = /
    path = /</code></pre>
</div>
<p>Set a password for the daemon in /etc/rsyncd.secrets, and set the owner/group of that file to root:root with 600 permissions. The password file format looks like this.</p>
<div>
  <pre><code class='bash'>#/etc/rsyncd.secrets
    root:SuperSecretPasswordFTW</code></pre>
</div>
<p>Open TCP port 873 for the pre-production host, an appropriate iptables rule would look something like this.</p>
<div>
  <pre><code class='bash'>iptables -I INPUT -s preprod-server -m tcp -p tcp --dport 873 --syn -j ACCEPT</code></pre>
</div>
<p>Finally run the following command to start up your temporary rsync daemon on the production host.</p>
<div>
  <pre><code class='bash'>rsync --daemon</code></pre>
</div>
<p>Now you should have all the components necessary to copy files over the network using the rsync protocol, an rsync client on the pre-production server, and an rsync server on the production server. Your command should look something like this.</p>
<div>
  <pre><code class='bash'>rsync -av root@prod-server::root/home/ /home</code></pre>
</div>
<p>Yet another way of saying the same thing, but also copying any special permissions on the top-level directory of home to the /home directory on the pre-prod server.</p>
<div>
  <pre><code class='bash'>rsync -av root@prod-server::root/home /</code></pre>
</div>
<p>The rsync url components are user (root), followed by an @, hostname (prod-server), followed by a separator (::), followed by the share name (root), followed by the source directory with, or without an optional trailing-slash.</p>

<p>Once the rsync job has finished on the pre-production server, you can run the following to kill off the daemon, and remove your temporary iptables rule.</p>
<div>
  <pre><code class='bash'>killall -9 rsync
    iptables -D INPUT -s preprod-server -m tcp -p tcp --dport 873 --syn -j ACCEPT</code></pre>
</div>
<h2 id='advanced_rsync_usage'>Advanced rsync usage</h2>

<h3 id='blocklevel_replication'>block-level replication</h3>

<p>In theory you would want to use the following option to update block-level changes on large files.</p>

<ul>
<li><code>--inplace</code>: rsync writes updated data directly to a file, instead of making a copy and moving it into place. * I strongly advise you to RTFM on this one, it comes with several warnings. But from what I understand, this option was added to rsync for cloning large files such as databases. Both server&#39;s rsync programs need to support the in-place option for this to work, otherwise it will give you an error.</li>
</ul>

<p>I usually kick off a large rysnc job on a hot database, and run one or even a few catch-up jobs on a cold database before the final switch in any large-scale data migration. What that means is you can run rsync on a running database, but you will not get a consistent Oracle DBF file on your pre-production host during a hot run. It doesn&#39;t matter if you use the <code>--inplace</code> option, or not, on the first hot run. Either way, you probably will not get a consistent copy of the database.</p>

<p>However, on any subsequent cold run (when the database is shut down) <code>--inplace</code> can significantly reduce the amount of data written on the pre-production host. Because this particular option has the ability to do block-level updates to large files, when used on your final rsync catch-up job. I have witnessed rsync updating half a Terabyte worth of dbf files in close to half an hour, during a final cold run on a quiet weekend. I have also seen it take up to four hours to do just as much after close of business on a Friday night. Your mileage may vary from my results, probably the most significant variable in rsync performance is the amount of usage between the initial hot run and final cold run.</p>

<h3 id='extending_rsync_by_automation_with_bash'>Extending rsync by automation with Bash</h3>

<p>Lets say you have a long paired list of source and destination directories. For example, I might want to archive <code>/home/u/user1</code> on the prod server to <code>/home/user1</code> on the pre-prod server. The rsync rules of the trailing slashes on directories do come into play here.</p>

<p>So after playing around with some perl/sed, and awk to generate a list of source and destinations from a password file on the production server. I might have a file rsync-home.list containing syntactically correct paired rsync sources and destinations, which would look something like this.</p>
<div>
  <pre><code class='bash'>root@prod-server::root/home/a/alice /home
    root@prod-server::root/home/b/bob /home
    root@prod-server::root/u01/app/oracle /u01/app
    root@prod-server::root/home/c/charlie /home
    root@prod-server::root/home/d/dave /home
    root@prod-server::root/home/e/eve /home
    root@prod-server::root/home/m/mallory /home
    root@prod-server::root/home/t/trent /home
    root@prod-server::root/home/w/walter /home
    root@prod-server::root/usr/local/vendor /usr/local</code></pre>
</div>
<p>Unfortunately there is no switch for rsync to read such a list, and operate on it directly. However, it is fairly easy to script with a bash one-liner, like so.</p>
<div>
  <pre><code class='bash'>RSYNC_PASSWORD=&quot;SuperSecretPasswordFTW&quot;; cat rsync-home.list | while read LINE; do rsync -av --progress $LINE; done</code></pre>
</div>
<p>The <code>RSYNC_PASSWORD</code> is an environment variable you can set to avoid having to type in the actual password for the rsync daemon, just be aware it will show up in your .bash_history file, and output from <code>ps -ef</code>. So it is advisable to not use the same password as your root account for the purposes of rsync.</p>

<h3 id='hunting_down_symlinks_in_the_archive_tree'>Hunting down symlinks in the archive tree</h3>

<p>Remember when I said you usually don&#39;t want to copy what a symlink points at, rather copy the pointer (symlink file) itself. If you want a quick and easy way to make a list of symlinked directories within the <code>/u01</code> tree on your production server, you can pair <code>find</code>, and <code>awk</code> commands to generate a list like this. The <code>-type l</code> option tells <code>find</code> to look for symlinks, the <code>-xtype d</code> option tells find to look for symlinks pointing at directories. The <code>$NF</code> variable in <code>awk</code> returns the last field from the long-list <code>ls -l</code> output.</p>
<div>
  <pre><code class='bash'>find /u01 -type l -xtype d -exec ls -l {} ; | awk '{ print $NF }'</code></pre>
</div>
<p>Which returns a handy little list of items remaining to be copied over to our pre-prod server by rsync. The couple of returned entries without a leading-slash can be thrown out, those are links within the <code>/u01</code> tree and would therefore be copied as a result of running an rsync job on <code>/u01</code>.</p>
<div>
  <pre><code class='bash'>/u04/app/oracle/RMAN
    /u03/app/oracle/arclogs
    /u05/app/oracle/exports
    /u02/app/oracle/oradata/fooprod
    /u06/app/oracle/oradata/foopreprd
    client
    /u08
    linux</code></pre>
</div>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2 Cent Tip - Extend (resize) a whole device partition.]]></title>
    <link href="/2010/09/02/2-cent-tip-extend-resize-a-whole-device-partition.html"/>
    <updated>2010-09-02T00:00:00-04:00</updated>
    <id>/2010/09/02/2-cent-tip-extend-resize-a-whole-device-partition</id>
    <content type="html"><![CDATA[<h1 id='2_cent_tip__extend_resize_a_whole_device_partition'>2 Cent Tip - Extend (resize) a whole device partition.</h1>

<p>2010 Sep 2</p>

<p>Occasionally I have to resize partitions on iSCSI or Fiber-Channel attached SAN storage. Both technologies allow you to easily extend the available storage for a host by extending LUNs, or volumes. A common problem after extending the size of the LUN, or volume, is resizing partitions to fill out the new size.</p>

<p>For the most part, I usually fire up <a href='http://partedmagic.com'>PartedMagic</a> and its a snap, even with Fiber-Channel attached enterprise storage. Once the HBAs (Host Bus Adapters) have been zoned to Fiber-Channel switches, then the HBAs do all the heavy lifting. In other words on Fiber-Channel, it doesn&#8217;t matter if you&#8217;re using PartedMagic, or <a href='http://www.knopper.net'>Knoppix</a>, the server just knows where the storage is and whether it is in an attached state. The only dependency for this working on a Live boot disk are drivers for the HBA cards.</p>

<p>iSCSI is a bit different. Because, iSCSI relies on commodity Network Interface Cards, this technology is largely implemented in software. One perceived advantage is iSCSI may seem less complicated to use than Fiber-Channel storage. Unfortunately, in this case, PartedMagic did not have open-iscsi software, and I could install open-iscsi in the Knoppix Live ramdisk. However, because Knoppix came with an outdated iSCSI kernel module, it was not new enough to inter-operate with the open-iscsi software.</p>

<p>Furthermore, the version of <a href='http://www.gnu.org/software/parted/index.shtml'>parted</a> that shipped with RHEL 5 threw an incompatible filesystem error, refusing to modify the filesystem. So, in the end, I twiddled some bits on the partition table with fdisk, and used resize2fs to extend the partition.</p>

<p>Assuming you have a backup of the filesystem you are working on, you can proceed with the following steps to extend a single partition to the end of the extended volume. If you have multiple partitions on a volume, you may want to stick to more reliable methods of resizing and extending. If you screw up the cylinder boundaries on a device with multiple partitions, you&#8217;ll definitely lose data. A single partition, in this example, is a much simpler scenario.</p>

<p>The device name in this example is <code>/dev/mapper/u02</code>, the first partition is <code>/dev/mapper/u02p1</code>:</p>

<p>Run <code>fdisk -l /dev/mapper/u02</code> to get the starting cylinder.</p>
<div>
  <pre><code class='bash'>root@localhost:~# fdisk -l /dev/mapper/u02
    Disk /dev/mapper/u02: 100.9 GB, 108340550042 bytes

    255 heads, 63 sectors/track, 13171 cylinders
    Units = cylinders of 16065 * 512 = 8225280 bytes

              Device Boot      Start         End      Blocks   Id  System
    /dev/mapper/u02p1               1       13171   26450329   83  Linux</code></pre>
</div>
<p>Reboot the server after extending the volume or LUN on your SAN. You want to do this before extending the partition in your Operating System. The Operating System needs to re-read sector 0 on the extended SAN volume, before continuing. Note, that fdisk will report <strong>26109</strong> cylinders instead of <strong>13171</strong>, after rebooting the server.</p>

<p>Next, we will run: <code>fdisk /dev/mapper/u02</code>, and then hit the keys: <code>d, n, p, 1, [enter], [enter], w</code></p>
<div>
  <pre><code class='bash'>root@localhost:~# fdisk /dev/mapper/u02
    WARNING: DOS-compatible mode is deprecated. It's strongly recommended to
             switch off the mode (command 'c') and change display units to
             sectors (command 'u').

    Command (m for help): d
    Selected partition 1

    Command (m for help): n
    Command action
       e   extended
       p   primary partition (1-4)
    p
    Partition number (1-4): 1
    First cylinder (1-26109, default 1):
    Using default value 1
    Last cylinder, +cylinders or +size{K,M,G} (1-26109, default 26109):
    Using default value 26109

    Command (m for help): w
    The partition table has been altered!

    Calling ioctl() to re-read partition table.
    Syncing disks.</code></pre>
</div>
<p>Finally, run <code>resize2fs</code> on <code>/dev/mapper/u02p1</code>. If you are using ext3, you can do an on-line resize while the volume is mounted. It is probably safest to <code>umount</code> the partition to be re-sized, however.</p>
<div>
  <pre><code class='bash'>root@localhost:~# resize2fs /dev/mapper/u02p1
    resize2fs 1.39 (29-May-2006)
    Filesystem at /dev/mapper/u02p1 is mounted on /u02; on-line resizing required
    Performing an on-line resize of /dev/mapper/u02p1 to 52430127 (4k) blocks.
    The filesystem on /dev/mapper/u02p1 is now 52430127 blocks long.</code></pre>
</div>
<p>Refer to the <code>resize2fs</code> for more information on the command, and its proper usage.</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2 Cent Tip - Dynamic rdesktop resolution.]]></title>
    <link href="/2010/06/28/2-cent-tip-dynamic-rdesktop-resolution.html"/>
    <updated>2010-06-28T00:00:00-04:00</updated>
    <id>/2010/06/28/2-cent-tip-dynamic-rdesktop-resolution</id>
    <content type="html"><![CDATA[<p>So occasionally I do have to touch a Windows system, or use a Windows-only management tool (I&#8217;m looking at you VMware). Not that I have any problem with Microsoft or Windows, I&#8217;m really just more comfortable in a Unix-like environment. I do use the Open Source <code>rdesktop</code> utility to access Windows machine using version 5.0 of the Remote Desktop Protocol (RDP).</p>

<p>It&#8217;s a handy utility, but I really wish it would give me an appropriate resolution based on the current resolution of my laptop&#8217;s X Windows session. There is, in fact, a command line flag to alter the geometry of the remote desktop window. However, typing in <code>rdesktop -g 1280x1024</code> is much more tedious than typing in <code>rdesktop</code> on the command line interface.</p>

<p>So the simple solution is to put an alias in the <code>.bashrc</code> file, like so&#8230;</p>
<div>
  <pre><code class='bash'># ~/.bashrc
    rdesktop='rdesktop -g 1280x1024'</code></pre>
</div>
<p>However, on my laptop, the max resolution without an external monitor is 1600x900. So I still have to override the setting with <code>rdesktop -g 1280x1024</code> on the command line, any time I am running without an external monitor.</p>

<p>Another solution would be to use <code>awk</code> to find a smaller resolution from <code>xrandr</code>, then set that resolution in my <code>rdesktop</code> alias.</p>
<div>
  <pre><code class='bash'># ~/.bashrc
    RDESKTOP_SIZE=`xrandr | awk '{getline; getline; getline; print $1; exit;}'`

    alias rdesktop='rdesktop -g $RDESKTOP_SIZE'</code></pre>
</div>
<p>This <code>awk</code> command will skip the first three lines, from the xrandr output. That is two header lines, and the maximum resolution on the following line, which we&#8217;ll skip. I&#8217;ll take the next highest resolution and set that in the variable RDESKTOP_SIZE. Finally, I&#8217;ll use the variable <code>$RDESKTOP_SIZE</code> with the <code>-g</code> switch in <code>rdesktop</code> to properly set my alias.</p>

<p>Let us say you have two big monitors plugged into a port replicator. Perhaps you only want the <code>rdesktop</code> window to cover part of one screen. The following code will keep my <code>rdesktop</code> window smaller than one of the 1920x1200 screens on a spanned 3840x1200 resolution.</p>
<div>
  <pre><code class='bash'># ~/.bashrc
    RDESKTOP_SIZE=`xrandr | awk '{getline; getline; getline; print $1; exit;}'`

    if [ $RDESKTOP_SIZE == &quot;3840x1200&quot; ]; then
        RDESKTOP_SIZE=&quot;1820x1100&quot;
    fi

    alias rdesktop='rdesktop -g $RDESKTOP_SIZE'</code></pre>
</div>
<p>In other words, if I have two monitors at 1920x1200 each, their combined resolution is reported by <code>xrandr</code> as 3840x1200. I want to override the detected resolution to 100 pixels less than the resolution on one screen. Therefore I set the <code>$RDESKTOP_SIZE</code> variable to 1820x1100, before setting my <code>rdesktop</code> alias in <code>.bashrc</code>.</p>]]></content>
  </entry>
  
</feed>
